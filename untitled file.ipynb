# Graph Neural Networks for Node Classification

**COMP9418 Tutorial - Week XX**

- Instructor: [Your Name]
- School of Computer Science and Engineering, UNSW Sydney
- Notebook designed by [Your Name]
- Last Update: [Date]

---

## Overview

In this tutorial, we will explore different approaches for node classification on graph-structured data using the Cora citation network dataset. We will implement and compare three methods:

1. **Shallow Encoder** - A simple baseline that learns node embeddings directly
2. **Node2Vec** - Unsupervised graph embedding using random walks
3. **Graph Convolutional Network (GCN)** - A deep learning approach that leverages graph structure

By the end of this tutorial, you will understand:
- How to preprocess graph datasets
- Different approaches to learning node representations
- The advantages of incorporating graph structure in neural networks
- How to evaluate and compare different methods

---

## Technical Prerequisites

You will need the following packages installed:

```python
pip install tensorflow scikit-learn matplotlib seaborn numpy scipy
```

You will also need the custom `Graph` class from previous tutorials.

---

# Part 1: Setup and Data Loading

Let's start by importing all the necessary libraries and setting up our environment.

## Cell 1: Import Libraries

```python
# Data handling and numerical operations
import os
import urllib.request
import pickle
import random
import numpy as np
import scipy.sparse as sp

# Machine learning libraries
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Layer, Embedding, Dense, Input
from tensorflow.keras.optimizers.legacy import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import normalize
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.manifold import TSNE
from sklearn.metrics import accuracy_score

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Custom graph class (download if needed)
if not os.path.exists("Graph.py"):
    !wget 'https://raw.githubusercontent.com/UNSW-COMP9418/libraries/main/Graph.py'

from Graph import Graph

# Set plotting style
sns.set(style="whitegrid")
print("All libraries imported successfully!")
```

---

## Cell 2: Download Cora Dataset

The Cora dataset is a citation network where:
- **Nodes** represent research papers
- **Edges** represent citation relationships
- **Node features** are bag-of-words representations of paper abstracts
- **Node labels** are research area categories (7 classes)

```python
def download_cora_dataset():
    """Download Cora dataset files from Planetoid repository."""
    url = "https://github.com/kimiyoung/planetoid/raw/master/data"
    files = [
        "ind.cora.x", "ind.cora.tx", "ind.cora.allx",
        "ind.cora.y", "ind.cora.ty", "ind.cora.ally",
        "ind.cora.graph", "ind.cora.test.index"
    ]
    os.makedirs("cora_data", exist_ok=True)

    for filename in files:
        full_path = os.path.join("cora_data", filename)
        if not os.path.exists(full_path):
            print(f"Downloading {filename}...")
            urllib.request.urlretrieve(f"{url}/{filename}", full_path)
        else:
            print(f"{filename} already exists.")

# Download the dataset
download_cora_dataset()
```

---

## Cell 3: Load and Examine Raw Data

```python
def load_pickle_file(filepath):
    """Load pickle file with latin1 encoding."""
    with open(filepath, 'rb') as f:
        return pickle.load(f, encoding='latin1')

# Load dataset components
data_dir = "cora_data"
x_train = load_pickle_file(f"{data_dir}/ind.cora.x")
x_test = load_pickle_file(f"{data_dir}/ind.cora.tx")
x_all = load_pickle_file(f"{data_dir}/ind.cora.allx")
y_train = load_pickle_file(f"{data_dir}/ind.cora.y")
y_test = load_pickle_file(f"{data_dir}/ind.cora.ty")
y_all = load_pickle_file(f"{data_dir}/ind.cora.ally")
graph_dict = load_pickle_file(f"{data_dir}/ind.cora.graph")
test_indices = np.loadtxt(f"{data_dir}/ind.cora.test.index", dtype=int)

print("Raw data loaded!")
print(f"Training features shape: {x_train.shape}")
print(f"All features shape: {x_all.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Graph has {len(graph_dict)} nodes")
print(f"Example neighbors of node 0: {graph_dict[0][:5]}...")  # Show first 5 neighbors
```

---

# Part 2: Data Preprocessing

## Cell 4: Reconstruct Complete Dataset

The Cora dataset is split in a specific way. We need to reconstruct the complete feature and label matrices.

```python
# Determine total number of nodes
num_nodes = max(graph_dict.keys()) + 1

# Reconstruct full feature matrix
X_features = sp.lil_matrix((num_nodes, x_all.shape[1]))
X_features[:x_all.shape[0]] = x_all
for i, idx in enumerate(test_indices):
    X_features[idx] = x_test[i]

# Reconstruct full label matrix  
Y_labels = np.zeros((num_nodes, y_all.shape[1]))
Y_labels[:y_all.shape[0]] = y_all
for i, idx in enumerate(test_indices):
    Y_labels[idx] = y_test[i]

print(f"Complete dataset reconstructed:")
print(f"- Total nodes: {num_nodes}")
print(f"- Feature dimensions: {X_features.shape[1]}")
print(f"- Number of classes: {Y_labels.shape[1]}")
```

---

## Cell 5: Exercise - Preprocess Features and Labels

Complete the preprocessing function to normalize features and convert one-hot labels to integers.

```python
def preprocess_data(X_features, Y_labels, graph_dict):
    """Preprocess features, labels, and build adjacency matrix."""
    
    # TODO: Normalize node features using L2 norm per row
    # Hint: Use sklearn's normalize function with norm='l2', axis=1
    X_normalized = ...  # TODO
    
    # TODO: Convert one-hot labels to integers
    # Hint: Use np.argmax along axis=1
    y_labels = ...  # TODO
    
    # Build adjacency matrix
    num_nodes = X_normalized.shape[0]
    adj_matrix = sp.lil_matrix((num_nodes, num_nodes))
    for src, neighbors in graph_dict.items():
        for dst in neighbors:
            adj_matrix[src, dst] = 1
            adj_matrix[dst, src] = 1  # undirected graph
    
    return X_normalized, y_labels, adj_matrix

# Apply preprocessing
X_normalized, y_labels, adj_matrix = preprocess_data(X_features, Y_labels, graph_dict)

# Check results
print(f"Features normalized: {X_normalized.shape}")
print(f"Labels converted: {y_labels.shape}, unique classes: {len(np.unique(y_labels))}")
print(f"Adjacency matrix: {adj_matrix.shape}")
```

**Answer:**
```python
# X_normalized = normalize(X_features, norm='l2', axis=1)
# y_labels = np.argmax(Y_labels, axis=1)
```

---

## Cell 6: Build Graph Object and Create Data Splits

```python
def build_graph_from_adjacency(adj_matrix, directed=False):
    """Build custom Graph object from adjacency matrix."""
    G = Graph()
    adj_dense = adj_matrix.todense() if hasattr(adj_matrix, 'todense') else adj_matrix
    
    for i in range(adj_dense.shape[0]):
        for j in range(adj_dense.shape[1]):
            if adj_dense[i, j] != 0:
                G.add_edge(i, j, directed=directed)
    return G

def create_train_val_test_split(num_nodes, y_labels, test_size=0.3, val_size=0.2, random_state=42):
    """Create stratified train/validation/test splits."""
    node_indices = np.arange(num_nodes)
    
    # Split into train+val and test
    train_val_indices, test_indices = train_test_split(
        node_indices, stratify=y_labels, test_size=test_size, random_state=random_state
    )
    
    # Split train+val into train and val
    train_indices, val_indices = train_test_split(
        train_val_indices, stratify=y_labels[train_val_indices], 
        test_size=val_size, random_state=random_state
    )
    
    return train_indices, val_indices, test_indices

# Build graph and create splits
graph_object = build_graph_from_adjacency(adj_matrix, directed=False)
train_indices, val_indices, test_indices = create_train_val_test_split(num_nodes, y_labels)

# Dataset statistics
num_classes = len(np.unique(y_labels))
num_features = X_normalized.shape[1]

print("=== DATASET STATISTICS ===")
print(f"Nodes: {num_nodes}")
print(f"Features per node: {num_features}")
print(f"Classes: {num_classes}")
print(f"Train nodes: {len(train_indices)}")
print(f"Validation nodes: {len(val_indices)}")
print(f"Test nodes: {len(test_indices)}")
```

---

# Part 3: Exploratory Data Analysis

## Cell 7: Visualize Class Distribution

```python
def plot_class_distribution(y_labels):
    """Plot distribution of node classes."""
    plt.figure(figsize=(8, 4))
    sns.countplot(x=y_labels)
    plt.title("Node Class Distribution in Cora Dataset")
    plt.xlabel("Class ID")
    plt.ylabel("Number of Nodes")
    plt.show()

plot_class_distribution(y_labels)
```

---

## Cell 8: t-SNE Visualization of Node Features

```python
def plot_feature_tsne(X_features, y_labels, title="t-SNE of Node Features"):
    """Plot t-SNE visualization of node features."""
    # Convert sparse matrix to dense if needed
    X_dense = X_features.toarray() if not isinstance(X_features, np.ndarray) else X_features
    
    # Run t-SNE (this may take a moment)
    print("Running t-SNE... (this may take 30-60 seconds)")
    tsne = TSNE(n_components=2, perplexity=30, random_state=42)
    X_tsne = tsne.fit_transform(X_dense)
    
    # Plot
    plt.figure(figsize=(8, 6))
    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_labels, cmap="tab10", s=10, alpha=0.8)
    plt.title(title)
    plt.xlabel("t-SNE Dimension 1")
    plt.ylabel("t-SNE Dimension 2")
    plt.colorbar(scatter, label="Class ID")
    plt.show()

plot_feature_tsne(X_normalized, y_labels, "t-SNE of Normalized Node Features")
```

---

# Part 4: Model 1 - Shallow Encoder (Baseline)

## Cell 9: Implement Shallow Encoder

A shallow encoder learns a unique embedding for each node and uses these embeddings for classification. This serves as our baseline.

```python
class ShallowEncoder(Model):
    """Shallow encoder model that learns node embeddings and classifies directly."""
    
    def __init__(self, num_nodes, embedding_dim, num_classes):
        super().__init__()
        self.embedding = Embedding(input_dim=num_nodes, output_dim=embedding_dim)
        self.classifier = Dense(num_classes, activation='softmax')

    def call(self, node_ids):
        embeddings = self.embedding(node_ids)  # Shape: (batch_size, embedding_dim)
        logits = self.classifier(embeddings)   # Shape: (batch_size, num_classes)
        return logits

print("Shallow Encoder class defined!")
```

---

## Cell 10: Exercise - Train Shallow Encoder

Complete the training function for the shallow encoder.

```python
def train_shallow_encoder(num_nodes, num_classes, train_indices, val_indices, test_indices, y_labels):
    """Train and evaluate shallow encoder model."""
    print("=== TRAINING SHALLOW ENCODER ===")
    
    # Hyperparameters
    embedding_dim = 32
    learning_rate = 0.01
    batch_size = 128
    epochs = 50  # Reduced for tutorial
    
    # TODO: Convert indices and labels to TensorFlow tensors
    train_node_ids = tf.convert_to_tensor(train_indices, dtype=tf.int32)
    train_labels = tf.convert_to_tensor(y_labels[train_indices], dtype=tf.int32)
    val_node_ids = tf.convert_to_tensor(val_indices, dtype=tf.int32)
    val_labels = tf.convert_to_tensor(y_labels[val_indices], dtype=tf.int32)
    test_node_ids = tf.convert_to_tensor(test_indices, dtype=tf.int32)
    test_labels = tf.convert_to_tensor(y_labels[test_indices], dtype=tf.int32)
    
    # TODO: Create and compile model
    model = ...  # TODO: Create ShallowEncoder instance
    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss=...,  # TODO: What loss function for multi-class classification?
        metrics=['accuracy']
    )
    
    # Train model
    history = model.fit(
        x=train_node_ids,
        y=train_labels,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(val_node_ids, val_labels),
        verbose=1
    )
    
    # Evaluate on test set
    test_loss, test_accuracy = model.evaluate(test_node_ids, test_labels, verbose=0)
    print(f"Shallow Encoder Test Accuracy: {test_accuracy:.4f}")
    
    return test_accuracy, history

# Train the model
shallow_encoder_accuracy, history = train_shallow_encoder(
    num_nodes, num_classes, train_indices, val_indices, test_indices, y_labels
)
```

**Answer:**
```python
# model = ShallowEncoder(num_nodes, embedding_dim, num_classes)
# loss=tf.keras.losses.SparseCategoricalCrossentropy()
```

---

## Cell 11: Plot Training Progress

```python
def plot_training_history(history, title):
    """Plot training and validation accuracy over epochs."""
    plt.figure(figsize=(8, 4))
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title(f"{title} Training Progress")
    plt.legend()
    plt.grid(True)
    plt.show()

plot_training_history(history, "Shallow Encoder")
```

---

# Part 5: Model 2 - Node2Vec Embeddings

## Cell 12: Random Walk Generation

Node2Vec learns embeddings by performing random walks on the graph and using skip-gram training.

```python
def generate_random_walks(graph_object, num_walks=10, walk_length=20):
    """Generate random walks for Node2Vec training."""
    walks = []
    nodes = list(graph_object)
    
    for _ in range(num_walks):
        random.shuffle(nodes)
        for start_node in nodes:
            walk = [start_node]
            while len(walk) < walk_length:
                current_node = walk[-1]
                neighbors = graph_object.children(current_node)
                if neighbors:
                    walk.append(random.choice(neighbors))
                else:
                    break
            walks.append(walk)
    return walks

def generate_skipgram_pairs(walks, window_size=5):
    """Generate skipgram training pairs from random walks."""
    pairs = []
    for walk in walks:
        for i, center_node in enumerate(walk):
            start = max(0, i - window_size)
            end = min(len(walk), i + window_size + 1)
            for j in range(start, end):
                if i != j:
                    pairs.append((center_node, walk[j]))
    return pairs

# Generate training data
print("Generating random walks...")
walks = generate_random_walks(graph_object, num_walks=5, walk_length=10)  # Reduced for tutorial
pairs = generate_skipgram_pairs(walks, window_size=3)
print(f"Generated {len(pairs)} training pairs from {len(walks)} walks")
```

---

## Cell 13: Exercise - Implement Negative Sampling

```python
def get_negative_samples(vocab_size, exclude, k=5):
    """Sample negative nodes for contrastive learning."""
    negatives = []
    while len(negatives) < k:
        candidate = random.randint(0, vocab_size - 1)
        if candidate != exclude:
            negatives.append(candidate)
    return negatives

# TODO: Complete the Node2Vec training step function
@tf.function
def train_step(node_embeddings, optimizer, center_ids, positive_ids, negative_ids):
    with tf.GradientTape() as tape:
        # Get embeddings
        center_embed = tf.nn.embedding_lookup(node_embeddings, center_ids)     # [B, D]
        positive_embed = tf.nn.embedding_lookup(node_embeddings, positive_ids) # [B, D]
        negative_embed = tf.nn.embedding_lookup(node_embeddings, negative_ids) # [B, K, D]
        
        # TODO: Compute positive scores (dot product)
        positive_scores = ...  # TODO: center_embed * positive_embed, sum over embedding dimension
        positive_loss = tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.ones_like(positive_scores), logits=positive_scores
        )
        
        # TODO: Compute negative scores
        negative_scores = tf.einsum('ij,ikj->ik', center_embed, negative_embed)  # [B, K]
        negative_loss = tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.zeros_like(negative_scores), logits=negative_scores
        )
        negative_loss = tf.reduce_sum(negative_loss, axis=1)
        
        # Total loss
        total_loss = tf.reduce_mean(positive_loss + negative_loss)
    
    # Apply gradients
    gradients = tape.gradient(total_loss, [node_embeddings])
    optimizer.apply_gradients(zip(gradients, [node_embeddings]))
    return total_loss

print("Node2Vec training functions defined!")
```

**Answer:**
```python
# positive_scores = tf.reduce_sum(center_embed * positive_embed, axis=1)
```

---

## Cell 14: Train Node2Vec Embeddings

```python
def train_node2vec_embeddings(pairs, num_nodes, embedding_dim=32, learning_rate=0.01, 
                            num_epochs=3, batch_size=256, neg_samples=5):
    """Train Node2Vec embeddings using skip-gram with negative sampling."""
    print("=== TRAINING NODE2VEC EMBEDDINGS ===")
    
    # Initialize embeddings and optimizer
    node_embeddings = tf.Variable(tf.random.normal([num_nodes, embedding_dim]), trainable=True)
    optimizer = Adam(learning_rate=learning_rate)
    
    # Training loop
    print("Training Node2Vec embeddings...")
    for epoch in range(num_epochs):
        np.random.shuffle(pairs)
        batches = [pairs[i:i+batch_size] for i in range(0, len(pairs), batch_size)]
        epoch_losses = []
        
        for batch in batches:
            center_ids = np.array([center for center, _ in batch])
            positive_ids = np.array([positive for _, positive in batch])
            negative_ids = np.array([
                get_negative_samples(num_nodes, exclude=pos, k=neg_samples)
                for pos in positive_ids
            ])
            
            loss = train_step(node_embeddings, optimizer, center_ids, positive_ids, negative_ids)
            epoch_losses.append(loss.numpy())
        
        print(f"Epoch {epoch+1}/{num_epochs}, Average Loss: {np.mean(epoch_losses):.4f}")
    
    return node_embeddings.numpy()

# Train Node2Vec embeddings
node2vec_embeddings = train_node2vec_embeddings(pairs, num_nodes)
print(f"Node2Vec embeddings shape: {node2vec_embeddings.shape}")
```

---

## Cell 15: Evaluate Node2Vec Embeddings

```python
def evaluate_embeddings(embeddings, X_normalized, train_indices, test_indices, y_labels):
    """Evaluate embeddings using logistic regression."""
    
    # Train classifier on embeddings only
    clf_embeddings = LogisticRegression(max_iter=1000)
    clf_embeddings.fit(embeddings[train_indices], y_labels[train_indices])
    test_acc_embeddings = clf_embeddings.score(embeddings[test_indices], y_labels[test_indices])
    
    # Train classifier on combined features (embeddings + original features)
    X_combined = np.hstack([embeddings, X_normalized.toarray()])
    clf_combined = LogisticRegression(max_iter=1000)
    clf_combined.fit(X_combined[train_indices], y_labels[train_indices])
    test_acc_combined = clf_combined.score(X_combined[test_indices], y_labels[test_indices])
    
    # Compare with raw features baseline
    X_dense = X_normalized.toarray()
    clf_raw = LogisticRegression(max_iter=1000)
    clf_raw.fit(X_dense[train_indices], y_labels[train_indices])
    test_acc_raw = clf_raw.score(X_dense[test_indices], y_labels[test_indices])
    
    print("=== NODE2VEC EVALUATION ===")
    print(f"Node2Vec Embeddings Test Accuracy: {test_acc_embeddings:.4f}")
    print(f"Combined Features Test Accuracy: {test_acc_combined:.4f}")
    print(f"Raw Features Test Accuracy: {test_acc_raw:.4f}")
    
    return test_acc_embeddings, test_acc_combined, test_acc_raw

# Evaluate embeddings
node2vec_acc, combined_acc, raw_features_acc = evaluate_embeddings(
    node2vec_embeddings, X_normalized, train_indices, test_indices, y_labels
)
```

---

## Cell 16: Visualize Node2Vec Embeddings

```python
# Visualize Node2Vec embeddings using t-SNE
plot_feature_tsne(node2vec_embeddings, y_labels, "t-SNE of Node2Vec Embeddings")
```

---

# Part 6: Model 3 - Graph Convolutional Network (GCN)

## Cell 17: Adjacency Matrix Normalization

GCNs require normalized adjacency matrices for stable training.

```python
def normalize_adjacency_matrix(adj_matrix):
    """Normalize adjacency matrix: A_hat = D^(-1/2) * (A + I) * D^(-1/2)"""
    
    # Add self-loops: A + I
    adj_with_self_loops = adj_matrix + sp.eye(adj_matrix.shape[0])
    
    # Compute degree matrix D
    degree_vector = np.array(adj_with_self_loops.sum(axis=1)).flatten()
    degree_inv_sqrt = 1.0 / np.sqrt(degree_vector)
    degree_inv_sqrt[np.isinf(degree_inv_sqrt)] = 0.0
    degree_inv_sqrt_matrix = sp.diags(degree_inv_sqrt)
    
    # Normalize: D^(-1/2) * (A + I) * D^(-1/2)
    adj_normalized = degree_inv_sqrt_matrix @ adj_with_self_loops @ degree_inv_sqrt_matrix
    return adj_normalized

def sparse_to_tf_sparse_tensor(sparse_matrix):
    """Convert scipy sparse matrix to TensorFlow SparseTensor."""
    sparse_coo = sparse_matrix.tocoo()
    indices = np.vstack((sparse_coo.row, sparse_coo.col)).T
    return tf.SparseTensor(
        indices=indices,
        values=sparse_coo.data.astype(np.float32),
        dense_shape=sparse_coo.shape
    )

# Prepare normalized adjacency matrix
adj_normalized = normalize_adjacency_matrix(adj_matrix)
adj_tf = sparse_to_tf_sparse_tensor(adj_normalized)
print("Adjacency matrix normalized and converted to TensorFlow format")
```

---

## Cell 18: Exercise - Implement GCN Layer

```python
class GCNLayer(tf.keras.layers.Layer):
    """Graph Convolutional Layer: H' = σ(A_hat * H * W + H * B)"""
    
    def __init__(self, output_dim):
        super().__init__()
        self.output_dim = output_dim
        # TODO: Create two Dense layers - one for graph convolution, one for residual
        self.weight_transform = ...  # TODO: Dense layer without bias
        self.bias_transform = ...   # TODO: Dense layer without bias

    def call(self, features, adj_normalized):
        # TODO: Apply graph convolution: A_hat * H * W
        transformed_features = self.weight_transform(features)
        graph_conv = tf.sparse.sparse_dense_matmul(adj_normalized, transformed_features)
        
        # TODO: Apply residual connection: H * B
        residual = ...  # TODO: Apply bias_transform to features
        
        return graph_conv + residual

print("GCN Layer class defined!")
```

**Answer:**
```python
# self.weight_transform = tf.keras.layers.Dense(output_dim, use_bias=False)
# self.bias_transform = tf.keras.layers.Dense(output_dim, use_bias=False)
# residual = self.bias_transform(features)
```

---

## Cell 19: Complete GCN Model

```python
class GCNModel(tf.keras.Model):
    """Two-layer Graph Convolutional Network."""
    
    def __init__(self, hidden_dim, num_classes):
        super().__init__()
        self.gcn_layer1 = GCNLayer(hidden_dim)
        self.gcn_layer2 = GCNLayer(num_classes)

    def call(self, features, adj_normalized, training=False):
        # First GCN layer with ReLU activation
        hidden = tf.nn.relu(self.gcn_layer1(features, adj_normalized))
        
        # Second GCN layer (output logits)
        logits = self.gcn_layer2(hidden, adj_normalized)
        return logits

print("GCN Model class defined!")
```

---

## Cell 20: Train GCN Model

```python
def train_gcn_model(X_normalized, adj_tf, train_indices, val_indices, test_indices, y_labels, num_classes):
    """Train and evaluate GCN model."""
    print("=== TRAINING GRAPH CONVOLUTIONAL NETWORK ===")
    
    # Hyperparameters
    hidden_dim = 16
    learning_rate = 0.01
    num_epochs = 50  # Reduced for tutorial
    
    # Prepare data
    X_tf = tf.convert_to_tensor(X_normalized.toarray(), dtype=tf.float32)
    y_onehot = to_categorical(y_labels, num_classes=num_classes)
    y_tf = tf.convert_to_tensor(y_onehot, dtype=tf.float32)
    
    # Convert indices to tensors
    train_indices_tf = tf.convert_to_tensor(train_indices, dtype=tf.int32)
    val_indices_tf = tf.convert_to_tensor(val_indices, dtype=tf.int32)
    test_indices_tf = tf.convert_to_tensor(test_indices, dtype=tf.int32)
    
    # Initialize model and optimizer
    gcn_model = GCNModel(hidden_dim, num_classes)
    optimizer = Adam(learning_rate=learning_rate)
    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    
    # Training metrics
    train_losses = []
    val_accuracies = []
    
    # Training step
    @tf.function
    def train_step():
        with tf.GradientTape() as tape:
            logits = gcn_model(X_tf, adj_tf, training=True)
            train_logits = tf.gather(logits, train_indices_tf)
            train_labels = tf.gather(y_tf, train_indices_tf)
            loss = loss_fn(train_labels, train_logits)
        
        gradients = tape.gradient(loss, gcn_model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, gcn_model.trainable_variables))
        return loss
    
    # Training loop
    print("Training GCN...")
    for epoch in range(num_epochs):
        # Train step
        loss = train_step()
        train_losses.append(loss.numpy())
        
        # Validation accuracy
        logits = gcn_model(X_tf, adj_tf, training=False)
        val_logits = tf.gather(logits, val_indices_tf)
        val_predictions = tf.argmax(val_logits, axis=1)
        val_true_labels = tf.argmax(tf.gather(y_tf, val_indices_tf), axis=1)
        val_accuracy = tf.reduce_mean(tf.cast(tf.equal(val_predictions, val_true_labels), tf.float32))
        val_accuracies.append(val_accuracy.numpy())
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.numpy():.4f}, Val Acc: {val_accuracy.numpy():.4f}")
    
    # Final evaluation
    final_logits = gcn_model(X_tf, adj_tf, training=False)
    test_logits = tf.gather(final_logits, test_indices_tf)
    test_predictions = tf.argmax(test_logits, axis=1)
    test_true_labels = tf.argmax(tf.gather(y_tf, test_indices_tf), axis=1)
    test_accuracy = tf.reduce_mean(tf.cast(tf.equal(test_predictions, test_true_labels), tf.float32))
    
    print(f"GCN Test Accuracy: {test_accuracy.numpy():.4f}")
    
    return gcn_model, test_accuracy.numpy(), train_losses, val_accuracies

# Train GCN model
gcn_model, gcn_test_accuracy, train_losses, val_accuracies = train_gcn_model(
    X_normalized, adj_tf, train_indices, val_indices, test_indices, y_labels, num_classes
)
```

---

## Cell 21: Plot GCN Training Progress

```python
# Plot training progress
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("GCN Training Loss")
plt.grid(True)
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(val_accuracies, label="Validation Accuracy", color="green")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("GCN Validation Accuracy")
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()
```

---

## Cell 22: Exercise - Extract and Visualize GCN Embeddings

Complete the function to extract deep embeddings from the first GCN layer.

```python
def extract_gcn_embeddings(gcn_model, X_tf, adj_tf):
    """Extract deep embeddings from the first GCN layer."""
    @tf.function
    def get_embeddings():
        # TODO: Get embeddings from the first GCN layer
        hidden = gcn_model.gcn_layer1(X_tf, adj_tf)
        return ...  # TODO: Apply ReLU activation
    
    return get_embeddings().numpy()

# Extract and visualize GCN embeddings
X_tf = tf.convert_to_tensor(X_normalized.toarray(), dtype=tf.float32)
gcn_embeddings = extract_gcn_embeddings(gcn_model, X_tf, adj_tf)
plot_feature_tsne(gcn_embeddings, y_labels, "t-SNE of GCN Deep Embeddings")
```

**Answer:**
```python
# return tf.nn.relu(hidden)
```

---

# Part 7: Results Analysis and Comparison

## Cell 23: Summary of Results

```python
print("\n" + "="*60)
print("FINAL RESULTS SUMMARY")
print("="*60)
print(f"Shallow Encoder Test Accuracy:     {shallow_encoder_accuracy:.4f}")
print(f"Node2Vec Embeddings Test Accuracy: {node2vec_acc:.4f}")
print(f"Combined Features Test Accuracy:   {combined_acc:.4f}")
print(f"Raw Features Test Accuracy:        {raw_features_acc:.4f}")
print(f"GCN Test Accuracy:                 {gcn_test_accuracy:.4f}")
print("="*60)
```

---

## Cell 24: Visual Comparison of All Methods

```python
# Create comparison plot
methods = ['Shallow\nEncoder', 'Node2Vec\nEmbeddings', 'Combined\nFeatures', 'Raw\nFeatures', 'GCN']
accuracies = [shallow_encoder_accuracy, node2vec_acc, combined_acc, raw_features_acc, gcn_test_accuracy]

plt.figure(figsize=(10, 6))
bars = plt.bar(methods, accuracies, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral'])
plt.title('Node Classification Performance Comparison')
plt.ylabel('Test Accuracy')
plt.ylim(0, 1)

# Add value labels on bars
for bar, acc in zip(bars, accuracies):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
```

---

# Part 8: Discussion and Analysis

## Cell 25: Key Insights

```python
print("=== KEY INSIGHTS FROM THE TUTORIAL ===")
print()
print("1. SHALLOW ENCODER:")
print("   - Simple baseline that learns unique embeddings for each node")
print("   - Does not leverage graph structure or node features")
print("   - Performance depends on having enough training data per node")
print()
print("2. NODE2VEC:")
print("   - Unsupervised method that captures graph structure through random walks")
print("   - Can be combined with original features for better performance")
print("   - Learns embeddings that preserve local neighborhood information")
print()
print("3. GRAPH CONVOLUTIONAL NETWORK:")
print("   - Leverages both graph structure AND node features")
print("   - Uses message passing to aggregate information from neighbors")
print("   - Often achieves best performance on graph-structured data")
print()
print("4. FEATURE ANALYSIS:")
print("   - Raw features alone can be quite effective for some datasets")
print("   - Combining graph embeddings with features often improves results")
print("   - Graph structure provides complementary information to node features")
```

---

## Cell 26: Exercise - Experiment with Hyperparameters

Try modifying some hyperparameters and observe the effects. Complete this experimental analysis:

```python
def quick_gcn_experiment(hidden_dim, learning_rate):
    """Run a quick GCN experiment with different hyperparameters."""
    
    # TODO: Create a new GCN model with the specified hidden_dim
    experimental_model = ...  # TODO
    
    # TODO: Create optimizer with specified learning_rate
    optimizer = ...  # TODO
    
    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    
    # Quick training (just 10 epochs)
    X_tf = tf.convert_to_tensor(X_normalized.toarray(), dtype=tf.float32)
    y_onehot = to_categorical(y_labels, num_classes=num_classes)
    y_tf = tf.convert_to_tensor(y_onehot, dtype=tf.float32)
    train_indices_tf = tf.convert_to_tensor(train_indices, dtype=tf.int32)
    test_indices_tf = tf.convert_to_tensor(test_indices, dtype=tf.int32)
    
    @tf.function
    def train_step():
        with tf.GradientTape() as tape:
            logits = experimental_model(X_tf, adj_tf, training=True)
            train_logits = tf.gather(logits, train_indices_tf)
            train_labels = tf.gather(y_tf, train_indices_tf)
            loss = loss_fn(train_labels, train_logits)
        
        gradients = tape.gradient(loss, experimental_model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, experimental_model.trainable_variables))
        return loss
    
    # Quick training
    for epoch in range(10):
        train_step()
    
    # Evaluate
    final_logits = experimental_model(X_tf, adj_tf, training=False)
    test_logits = tf.gather(final_logits, test_indices_tf)
    test_predictions = tf.argmax(test_logits, axis=1)
    test_true_labels = tf.argmax(tf.gather(y_tf, test_indices_tf), axis=1)
    test_accuracy = tf.reduce_mean(tf.cast(tf.equal(test_predictions, test_true_labels), tf.float32))
    
    return test_accuracy.numpy()

# Experiment with different hyperparameters
print("=== HYPERPARAMETER EXPERIMENTS ===")
print("Original GCN (hidden_dim=16, lr=0.01):", f"{gcn_test_accuracy:.4f}")

# TODO: Try different hidden dimensions
hidden_dims = [8, 32, 64]
for dim in hidden_dims:
    acc = quick_gcn_experiment(dim, 0.01)
    print(f"Hidden dim {dim}: {acc:.4f}")

# TODO: Try different learning rates  
learning_rates = [0.005, 0.02, 0.05]
for lr in learning_rates:
    acc = quick_gcn_experiment(16, lr)
    print(f"Learning rate {lr}: {acc:.4f}")
```

**Answer:**
```python
# experimental_model = GCNModel(hidden_dim, num_classes)
# optimizer = Adam(learning_rate=learning_rate)
```

---

## Cell 27: Conclusion

```python
print("=== TUTORIAL COMPLETE! ===")
print()
print("🎉 Congratulations! You have successfully:")
print("   ✓ Loaded and preprocessed a real graph dataset")
print("   ✓ Implemented three different node classification approaches")
print("   ✓ Compared the performance of different methods")
print("   ✓ Visualized embeddings and results")
print("   ✓ Experimented with hyperparameters")
print()
print("🔍 Key Takeaways:")
print("   • Graph structure provides valuable information for node classification")
print("   • Different methods have different strengths and use cases")
print("   • GCNs can effectively combine graph structure with node features")
print("   • Visualization helps understand what models learn")
print()
print("🚀 Next Steps:")
print("   • Try implementing other GNN variants (GraphSAGE, GAT)")
print("   • Experiment with other graph datasets")
print("   • Explore graph-level tasks (graph classification)")
print("   • Study more advanced graph neural network architectures")
```

---

# Appendix: Additional Exercises (Optional)

## Exercise A: Implement GraphSAGE Sampling

For advanced students, try implementing a simple version of GraphSAGE sampling:

```python
def sample_neighbors(graph_object, node, num_samples=5):
    """Sample a fixed number of neighbors for GraphSAGE."""
    neighbors = graph_object.children(node)
    if len(neighbors) <= num_samples:
        return neighbors
    else:
        return random.sample(neighbors, num_samples)

# TODO: Use this in a modified GCN layer that samples neighbors
# This is left as an advanced exercise for interested students
```

## Exercise B: Attention Mechanism

Try adding attention weights to the GCN layer:

```python
class AttentionGCNLayer(tf.keras.layers.Layer):
    """GCN Layer with attention mechanism."""
    
    def __init__(self, output_dim):
        super().__init__()
        self.output_dim = output_dim
        self.weight_transform = tf.keras.layers.Dense(output_dim, use_bias=False)
        # TODO: Add attention mechanism
        # This is left as an advanced exercise
    
    def call(self, features, adj_normalized):
        # TODO: Implement attention-based aggregation
        pass
```

---

**End of Tutorial**

*This tutorial provided a comprehensive introduction to Graph Neural Networks for node classification. You learned three different approaches and gained hands-on experience with real graph data. Keep exploring the exciting field of graph machine learning!*