# Graph Neural Networks for Node Classification

**COMP9418 Tutorial - Week XX**

- Instructor: [Your Name]
- School of Computer Science and Engineering, UNSW Sydney
- Notebook designed by [Your Name]
- Last Update: [Date]

---

## Overview

In this tutorial, we will explore different approaches for node classification on graph-structured data using the Cora citation network dataset. We will implement and compare three methods:

1. **Shallow Encoder** - A simple baseline that learns node embeddings directly
2. **Node2Vec** - Unsupervised graph embedding using random walks
3. **Graph Convolutional Network (GCN)** - A deep learning approach that leverages graph structure

By the end of this tutorial, you will understand:
- How to preprocess graph datasets
- Different approaches to learning node representations
- The advantages of incorporating graph structure in neural networks
- How to evaluate and compare different methods

---

## Technical Prerequisites

You will need the following packages installed:

```python
pip install tensorflow scikit-learn matplotlib seaborn numpy scipy
```

You will also need the custom `Graph` class from previous tutorials.

---

# Part 1: Setup and Data Loading

Let's start by importing all the necessary libraries and setting up our environment.

## Cell 1: Import Libraries

```python
# Data handling and numerical operations
import os
import urllib.request
import pickle
import random
import numpy as np
import scipy.sparse as sp

# Machine learning libraries
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Layer, Embedding, Dense, Input
from tensorflow.keras.optimizers.legacy import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import normalize
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.manifold import TSNE
from sklearn.metrics import accuracy_score

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Custom graph class (download if needed)
if not os.path.exists("Graph.py"):
    !wget 'https://raw.githubusercontent.com/UNSW-COMP9418/libraries/main/Graph.py'

from Graph import Graph

# Set plotting style
sns.set(style="whitegrid")
print("All libraries imported successfully!")
```

---

## Cell 2: Download Cora Dataset

The Cora dataset is a citation network where:
- **Nodes** represent research papers
- **Edges** represent citation relationships
- **Node features** are bag-of-words representations of paper abstracts
- **Node labels** are research area categories (7 classes)

```python
def download_cora_dataset():
    """Download Cora dataset files from Planetoid repository."""
    url = "https://github.com/kimiyoung/planetoid/raw/master/data"
    files = [
        "ind.cora.x", "ind.cora.tx", "ind.cora.allx",
        "ind.cora.y", "ind.cora.ty", "ind.cora.ally",
        "ind.cora.graph", "ind.cora.test.index"
    ]
    os.makedirs("cora_data", exist_ok=True)

    for filename in files:
        full_path = os.path.join("cora_data", filename)
        if not os.path.exists(full_path):
            print(f"Downloading {filename}...")
            urllib.request.urlretrieve(f"{url}/{filename}", full_path)
        else:
            print(f"{filename} already exists.")

# Download the dataset
download_cora_dataset()
```

---

## Cell 3: Load and Examine Raw Data

```python
def load_pickle_file(filepath):
    """Load pickle file with latin1 encoding."""
    with open(filepath, 'rb') as f:
        return pickle.load(f, encoding='latin1')

# Load dataset components
data_dir = "cora_data"
x_train = load_pickle_file(f"{data_dir}/ind.cora.x")
x_test = load_pickle_file(f"{data_dir}/ind.cora.tx")
x_all = load_pickle_file(f"{data_dir}/ind.cora.allx")
y_train = load_pickle_file(f"{data_dir}/ind.cora.y")
y_test = load_pickle_file(f"{data_dir}/ind.cora.ty")
y_all = load_pickle_file(f"{data_dir}/ind.cora.ally")
graph_dict = load_pickle_file(f"{data_dir}/ind.cora.graph")
test_indices = np.loadtxt(f"{data_dir}/ind.cora.test.index", dtype=int)

print("Raw data loaded!")
print(f"Training features shape: {x_train.shape}")
print(f"All features shape: {x_all.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Graph has {len(graph_dict)} nodes")
print(f"Example neighbors of node 0: {graph_dict[0][:5]}...")  # Show first 5 neighbors
```

---

# Part 2: Data Preprocessing

## Cell 4: Reconstruct Complete Dataset

The Cora dataset is split in a specific way. We need to reconstruct the complete feature and label matrices.

```python
# Determine total number of nodes
num_nodes = max(graph_dict.keys()) + 1

# Reconstruct full feature matrix
X_features = sp.lil_matrix((num_nodes, x_all.shape[1]))
X_features[:x_all.shape[0]] = x_all
for i, idx in enumerate(test_indices):
    X_features[idx] = x_test[i]

# Reconstruct full label matrix  
Y_labels = np.zeros((num_nodes, y_all.shape[1]))
Y_labels[:y_all.shape[0]] = y_all
for i, idx in enumerate(test_indices):
    Y_labels[idx] = y_test[i]

print(f"Complete dataset reconstructed:")
print(f"- Total nodes: {num_nodes}")
print(f"- Feature dimensions: {X_features.shape[1]}")
print(f"- Number of classes: {Y_labels.shape[1]}")
```

---

## Cell 5: Exercise - Preprocess Features and Labels

Complete the preprocessing function to normalize features and convert one-hot labels to integers.

```python
def preprocess_data(X_features, Y_labels, graph_dict):
    """Preprocess features, labels, and build adjacency matrix."""
    
    # TODO: Normalize node features using L2 norm per row
    # Hint: Use sklearn's normalize function with norm='l2', axis=1
    X_normalized = ...  # TODO
    
    # TODO: Convert one-hot labels to integers
    # Hint: Use np.argmax along axis=1
    y_labels = ...  # TODO
    
    # Build adjacency matrix
    num_nodes = X_normalized.shape[0]
    adj_matrix = sp.lil_matrix((num_nodes, num_nodes))
    for src, neighbors in graph_dict.items():
        for dst in neighbors:
            adj_matrix[src, dst] = 1
            adj_matrix[dst, src] = 1  # undirected graph
    
    return X_normalized, y_labels, adj_matrix

# Apply preprocessing
X_normalized, y_labels, adj_matrix = preprocess_data(X_features, Y_labels, graph_dict)

# Check results
print(f"Features normalized: {X_normalized.shape}")
print(f"Labels converted: {y_labels.shape}, unique classes: {len(np.unique(y_labels))}")
print(f"Adjacency matrix: {adj_matrix.shape}")
```

**Answer:**
```python
# X_normalized = normalize(X_features, norm='l2', axis=1)
# y_labels = np.argmax(Y_labels, axis=1)
```

---

## Cell 6: Build Graph Object and Create Data Splits

```python
def build_graph_from_adjacency(adj_matrix, directed=False):
    """Build custom Graph object from adjacency matrix."""
    G = Graph()
    adj_dense = adj_matrix.todense() if hasattr(adj_matrix, 'todense') else adj_matrix
    
    for i in range(adj_dense.shape[0]):
        for j in range(adj_dense.shape[1]):
            if adj_dense[i, j] != 0:
                G.add_edge(i, j, directed=directed)
    return G

def create_train_val_test_split(num_nodes, y_labels, test_size=0.3, val_size=0.2, random_state=42):
    """Create stratified train/validation/test splits."""
    node_indices = np.arange(num_nodes)
    
    # Split into train+val and test
    train_val_indices, test_indices = train_test_split(
        node_indices, stratify=y_labels, test_size=test_size, random_state=random_state
    )
    
    # Split train+val into train and val
    train_indices, val_indices = train_test_split(
        train_val_indices, stratify=y_labels[train_val_indices], 
        test_size=val_size, random_state=random_state
    )
    
    return train_indices, val_indices, test_indices

# Build graph and create splits
graph_object = build_graph_from_adjacency(adj_matrix, directed=False)
train_indices, val_indices, test_indices = create_train_val_test_split(num_nodes, y_labels)

# Dataset statistics
num_classes = len(np.unique(y_labels))
num_features = X_normalized.shape[1]

print("=== DATASET STATISTICS ===")
print(f"Nodes: {num_nodes}")
print(f"Features per node: {num_features}")
print(f"Classes: {num_classes}")
print(f"Train nodes: {len(train_indices)}")
print(f"Validation nodes: {len(val_indices)}")
print(f"Test nodes: {len(test_indices)}")
```

---

# Part 3: Exploratory Data Analysis

## Cell 7: Visualize Class Distribution

```python
def plot_class_distribution(y_labels):
    """Plot distribution of node classes."""
    plt.figure(figsize=(8, 4))
    sns.countplot(x=y_labels)
    plt.title("Node Class Distribution in Cora Dataset")
    plt.xlabel("Class ID")
    plt.ylabel("Number of Nodes")
    plt.show()

plot_class_distribution(y_labels)
```

---

## Cell 8: t-SNE Visualization of Node Features

```python
def plot_feature_tsne(X_features, y_labels, title="t-SNE of Node Features"):
    """Plot t-SNE visualization of node features."""
    # Convert sparse matrix to dense if needed
    X_dense = X_features.toarray() if not isinstance(X_features, np.ndarray) else X_features
    
    # Run t-SNE (this may take a moment)
    print("Running t-SNE... (this may take 30-60 seconds)")
    tsne = TSNE(n_components=2, perplexity=30, random_state=42)
    X_tsne = tsne.fit_transform(X_dense)
    
    # Plot
    plt.figure(figsize=(8, 6))
    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_labels, cmap="tab10", s=10, alpha=0.8)
    plt.title(title)
    plt.xlabel("t-SNE Dimension 1")
    plt.ylabel("t-SNE Dimension 2")
    plt.colorbar(scatter, label="Class ID")
    plt.show()

plot_feature_tsne(X_normalized, y_labels, "t-SNE of Normalized Node Features")
```

---

# Part 4: Model 1 - Shallow Encoder (Baseline)

## Cell 9: Implement Shallow Encoder

A shallow encoder learns a unique embedding for each node and uses these embeddings for classification. This serves as our baseline.

```python
class ShallowEncoder(Model):
    """Shallow encoder model that learns node embeddings and classifies directly."""
    
    def __init__(self, num_nodes, embedding_dim, num_classes):
        super().__init__()
        self.embedding = Embedding(input_dim=num_nodes, output_dim=embedding_dim)
        self.classifier = Dense(num_classes, activation='softmax')

    def call(self, node_ids):
        embeddings = self.embedding(node_ids)  # Shape: (batch_size, embedding_dim)
        logits = self.classifier(embeddings)   # Shape: (batch_size, num_classes)
        return logits

print("Shallow Encoder class defined!")
```

---

## Cell 10: Exercise - Train Shallow Encoder

Complete the training function for the shallow encoder.

```python
def train_shallow_encoder(num_nodes, num_classes, train_indices, val_indices, test_indices, y_labels):
    """Train and evaluate shallow encoder model."""
    print("=== TRAINING SHALLOW ENCODER ===")
    
    # Hyperparameters
    embedding_dim = 32
    learning_rate = 0.01
    batch_size = 128
    epochs = 50  # Reduced for tutorial
    
    # TODO: Convert indices and labels to TensorFlow tensors
    train_node_ids = tf.convert_to_tensor(train_indices, dtype=tf.int32)
    train_labels = tf.convert_to_tensor(y_labels[train_indices], dtype=tf.int32)
    val_node_ids = tf.convert_to_tensor(val_indices, dtype=tf.int32)
    val_labels = tf.convert_to_tensor(y_labels[val_indices], dtype=tf.int32)
    test_node_ids = tf.convert_to_tensor(test_indices, dtype=tf.int32)
    test_labels = tf.convert_to_tensor(y_labels[test_indices], dtype=tf.int32)
    
    # TODO: Create and compile model
    model = ...  # TODO: Create ShallowEncoder instance
    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss=...,  # TODO: What loss function for multi-class classification?
        metrics=['accuracy']
    )
    
    # Train model
    history = model.fit(
        x=train_node_ids,
        y=train_labels,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(val_node_ids, val_labels),
        verbose=1
    )
    
    # Evaluate on test set
    test_loss, test_accuracy = model.evaluate(test_node_ids, test_labels, verbose=0)
    print(f"Shallow Encoder Test Accuracy: {test_accuracy:.4f}")
    
    return test_accuracy, history

# Train the model
shallow_encoder_accuracy, history = train_shallow_encoder(
    num_nodes, num_classes, train_indices, val_indices, test_indices, y_labels
)
```

**Answer:**
```python
# model = ShallowEncoder(num_nodes, embedding_dim, num_classes)
# loss=tf.keras.losses.SparseCategoricalCrossentropy()
```

---

## Cell 11: Plot Training Progress

```python
def plot_training_history(history, title):
    """Plot training and validation accuracy over epochs."""
    plt.figure(figsize=(8, 4))
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title(f"{title} Training Progress")
    plt.legend()
    plt.grid(True)
    plt.show()

plot_training_history(history, "Shallow Encoder")
```

---

# Part 5: Model 2 - Node2Vec Embeddings

## Cell 12: Random Walk Generation

Node2Vec learns embeddings by performing random walks on the graph and using skip-gram training.

```python
def generate_random_walks(graph_object, num_walks=10, walk_length=20):
    """Generate random walks for Node2Vec training."""
    walks = []
    nodes = list(graph_object)
    
    for _ in range(num_walks):
        random.shuffle(nodes)
        for start_node in nodes:
            walk = [start_node]
            while len(walk) < walk_length:
                current_node = walk[-1]
                neighbors = graph_object.children(current_node)
                if neighbors:
                    walk.append(random.choice(neighbors))
                else:
                    break
            walks.append(walk)
    return walks

def generate_skipgram_pairs(walks, window_size=5):
    """Generate skipgram training pairs from random walks."""
    pairs = []
    for walk in walks:
        for i, center_node in enumerate(walk):
            start = max(0, i - window_size)
            end = min(len(walk), i + window_size + 1)
            for j in range(start, end):
                if i != j:
                    pairs.append((center_node, walk[j]))
    return pairs

# Generate training data
print("Generating random walks...")
walks = generate_random_walks(graph_object, num_walks=5, walk_length=10)  # Reduced for tutorial
pairs = generate_skipgram_pairs(walks, window_size=3)
print(f"Generated {len(pairs)} training pairs from {len(walks)} walks")
```

---

## Cell 13: Exercise - Implement Negative Sampling

```python
def get_negative_samples(vocab_size, exclude, k=5):
    """Sample negative nodes for contrastive learning."""
    negatives = []
    while len(negatives) < k:
        candidate = random.randint(0, vocab_size - 1)
        if candidate != exclude:
            negatives.append(candidate)
    return negatives

# TODO: Complete the Node2Vec training step function
@tf.function
def train_step(node_embeddings, optimizer, center_ids, positive_ids, negative_ids):
    with tf.GradientTape() as tape:
        # Get embeddings
        center_embed = tf.nn.embedding_lookup(node_embeddings, center_ids)     # [B, D]
        positive_embed = tf.nn.embedding_lookup(node_embeddings, positive_ids) # [B, D]
        negative_embed = tf.nn.embedding_lookup(node_embeddings, negative_ids) # [B, K, D]
        
        # TODO: Compute positive scores (dot product)
        positive_scores = ...  # TODO: center_embed * positive_embed, sum over embedding dimension
        positive_loss = tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.ones_like(positive_scores), logits=positive_scores
        )
        
        # TODO: Compute negative scores
        negative_scores = tf.einsum('ij,ikj->ik', center_embed, negative_embed)  # [B, K]
        negative_loss = tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.zeros_like(negative_scores), logits=negative_scores
        )
        negative_loss = tf.reduce_sum(negative_loss, axis=1)
        
        # Total loss
        total_loss = tf.reduce_mean(positive_loss + negative_loss)
    
    # Apply gradients
    gradients = tape.gradient(total_loss, [node_embeddings])
    optimizer.apply_gradients(zip(gradients, [node_embeddings]))
    return total_loss

print("Node2Vec training functions defined!")
```

**Answer:**
```python
# positive_scores = tf.reduce_sum(center_embed * positive_embed, axis=1)
```

---

## Cell 14: Train Node2Vec Embeddings

```python
def train_node2vec_embeddings(pairs, num_nodes, embedding_dim=32, learning_rate=0.01, 
                            num_epochs=3, batch_size=256, neg_samples=5):
    """Train Node2Vec embeddings using skip-gram with negative sampling."""
    print("=== TRAINING NODE2VEC EMBEDDINGS ===")
    
    # Initialize embeddings and optimizer
    node_embeddings = tf.Variable(tf.random.normal([num_nodes, embedding_dim]), trainable=True)
    optimizer = Adam(learning_rate=learning_rate)
    
    # Training loop
    print("Training Node2Vec embeddings...")
    for epoch in range(num_epochs):
        np.random.shuffle(pairs)
        batches = [pairs[i:i+batch_size] for i in range(0, len(pairs), batch_size)]
        epoch_losses = []
        
        for batch in batches:
            center_ids = np.array([center for center, _ in batch])
            positive_ids = np.array([positive for _, positive in batch])
            negative_ids = np.array([
                get_negative_samples(num_nodes, exclude=pos, k=neg_samples)
                for pos in positive_ids
            ])
            
            loss = train_step(node_embeddings, optimizer, center_ids, positive_ids, negative_ids)
            epoch_losses.append(loss.numpy())
        
        print(f"Epoch {epoch+1}/{num_epochs}, Average Loss: {np.mean(epoch_losses):.4f}")
    
    return node_embeddings.numpy()

# Train Node2Vec embeddings
node2vec_embeddings = train_node2vec_embeddings(pairs, num_nodes)
print(f"Node2Vec embeddings shape: {node2vec_embeddings.shape}")
```

---

## Cell 15: Evaluate Node2Vec Embeddings

```python
def evaluate_embeddings(embeddings, X_normalized, train_indices, test_indices, y_labels):
    """Evaluate embeddings using logistic regression."""
    
    # Train classifier on embeddings only
    clf_embeddings = LogisticRegression(max_iter=1000)
    clf_embeddings.fit(embeddings[train_indices], y_labels[train_indices])
    test_acc_embeddings = clf_embeddings.score(embeddings[test_indices], y_labels[test_indices])
    
    # Train classifier on combined features (embeddings + original features)
    X_combined = np.hstack([embeddings, X_normalized.toarray()])
    clf_combined = LogisticRegression(max_iter=1000)
    clf_combined.fit(X_combined[train_indices], y_labels[train_indices])
    test_acc_combined = clf_combined.score(X_combined[test_indices], y_labels[test_indices])
    
    # Compare with raw features baseline
    X_dense = X_normalized.toarray()
    clf_raw = LogisticRegression(max_iter=1000)
    clf_raw.fit(X_dense[train_indices], y_labels[train_indices])
    test_acc_raw = clf_raw.score(X_dense[test_indices], y_labels[test_indices])
    
    print("=== NODE2VEC EVALUATION ===")
    print(f"Node2Vec Embeddings Test Accuracy: {test_acc_embeddings:.4f}")
    print(f"Combined Features Test Accuracy: {test_acc_combined:.4f}")
    print(f"Raw Features Test Accuracy: {test_acc_raw:.4f}")
    
    return test_acc_embeddings, test_acc_combined, test_acc_raw

# Evaluate embeddings
node2vec_acc, combined_acc, raw_features_acc = evaluate_embeddings(
    node2vec_embeddings, X_normalized, train_indices, test_indices, y_labels
)
```

---

## Cell 16: Visualize Node2Vec Embeddings

```python
# Visualize Node2Vec embeddings using t-SNE
plot_feature_tsne(node2vec_embeddings, y_labels, "t-SNE of Node2Vec Embeddings")
```

---

# Part 6: Model 3 - Graph Convolutional Network (GCN)

## Cell 17: Adjacency Matrix Normalization

GCNs require normalized adjacency matrices for stable training.

```python
def normalize_adjacency_matrix(adj_matrix):
    """Normalize adjacency matrix: A_hat = D^(-1/2) * (A + I) * D^(-1/2)"""
    
    # Add self-loops: A + I
    adj_with_self_loops = adj_matrix + sp.eye(adj_matrix.shape[0])
    
    # Compute degree matrix D
    degree_vector = np.array(adj_with_self_loops.sum(axis=1)).flatten()
    degree_inv_sqrt = 1.0 / np.sqrt(degree_vector)
    degree_inv_sqrt[np.isinf(degree_inv_sqrt)] = 0.0
    degree_inv_sqrt_matrix = sp.diags(degree_inv_sqrt)
    
    # Normalize: D^(-1/2) * (A + I) * D^(-1/2)
    adj_normalized = degree_inv_sqrt_matrix @ adj_with_self_loops @ degree_inv_sqrt_matrix
    return adj_normalized

def sparse_to_tf_sparse_tensor(sparse_matrix):
    """Convert scipy sparse matrix to TensorFlow SparseTensor."""
    sparse_coo = sparse_matrix.tocoo()
    indices = np.vstack((sparse_coo.row, sparse_coo.col)).T
    return tf.SparseTensor(
        indices=indices,
        values=sparse_coo.data.astype(np.float32),
        dense_shape=sparse_coo.shape
    )

# Prepare normalized adjacency matrix
adj_normalized = normalize_adjacency_matrix(adj_matrix)
adj_tf = sparse_to_tf_sparse_tensor(adj_normalized)
print("Adjacency matrix normalized and converted to TensorFlow format")
```

---

## Cell 18: Exercise - Implement GCN Layer

```python
class GCNLayer(tf.keras.layers.Layer):
    """Graph Convolutional Layer: H' = œÉ(A_hat * H * W + H * B)"""
    
    def __init__(self, output_dim):
        super().__init__()
        self.output_dim = output_dim
        # TODO: Create two Dense layers - one for graph convolution, one for residual
        self.weight_transform = ...  # TODO: Dense layer without bias
        self.bias_transform = ...   # TODO: Dense layer without bias

    def call(self, features, adj_normalized):
        # TODO: Apply graph convolution: A_hat * H * W
        transformed_features = self.weight_transform(features)
        graph_conv = tf.sparse.sparse_dense_matmul(adj_normalized, transformed_features)
        
        # TODO: Apply residual connection: H * B
        residual = ...  # TODO: Apply bias_transform to features
        
        return graph_conv + residual

print("GCN Layer class defined!")
```

**Answer:**
```python
# self.weight_transform = tf.keras.layers.Dense(output_dim, use_bias=False)
# self.bias_transform = tf.keras.layers.Dense(output_dim, use_bias=False)
# residual = self.bias_transform(features)
```

---

## Cell 19: Complete GCN Model

```python
class GCNModel(tf.keras.Model):
    """Two-layer Graph Convolutional Network."""
    
    def __init__(self, hidden_dim, num_classes):
        super().__init__()
        self.gcn_layer1 = GCNLayer(hidden_dim)
        self.gcn_layer2 = GCNLayer(num_classes)

    def call(self, features, adj_normalized, training=False):
        # First GCN layer with ReLU activation
        hidden = tf.nn.relu(self.gcn_layer1(features, adj_normalized))
        
        # Second GCN layer (output logits)
        logits = self.gcn_layer2(hidden, adj_normalized)
        return logits

print("GCN Model class defined!")
```

---

## Cell 20: Train GCN Model

```python
def train_gcn_model(X_normalized, adj_tf, train_indices, val_indices, test_indices, y_labels, num_classes):
    """Train and evaluate GCN model."""
    print("=== TRAINING GRAPH CONVOLUTIONAL NETWORK ===")
    
    # Hyperparameters
    hidden_dim = 16
    learning_rate = 0.01
    num_epochs = 50  # Reduced for tutorial
    
    # Prepare data
    X_tf = tf.convert_to_tensor(X_normalized.toarray(), dtype=tf.float32)
    y_onehot = to_categorical(y_labels, num_classes=num_classes)
    y_tf = tf.convert_to_tensor(y_onehot, dtype=tf.float32)
    
    # Convert indices to tensors
    train_indices_tf = tf.convert_to_tensor(train_indices, dtype=tf.int32)
    val_indices_tf = tf.convert_to_tensor(val_indices, dtype=tf.int32)
    test_indices_tf = tf.convert_to_tensor(test_indices, dtype=tf.int32)
    
    # Initialize model and optimizer
    gcn_model = GCNModel(hidden_dim, num_classes)
    optimizer = Adam(learning_rate=learning_rate)
    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    
    # Training metrics
    train_losses = []
    val_accuracies = []
    
    # Training step
    @tf.function
    def train_step():
        with tf.GradientTape() as tape:
            logits = gcn_model(X_tf, adj_tf, training=True)
            train_logits = tf.gather(logits, train_indices_tf)
            train_labels = tf.gather(y_tf, train_indices_tf)
            loss = loss_fn(train_labels, train_logits)
        
        gradients = tape.gradient(loss, gcn_model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, gcn_model.trainable_variables))
        return loss
    
    # Training loop
    print("Training GCN...")
    for epoch in range(num_epochs):
        # Train step
        loss = train_step()
        train_losses.append(loss.numpy())
        
        # Validation accuracy
        logits = gcn_model(X_tf, adj_tf, training=False)
        val_logits = tf.gather(logits, val_indices_tf)
        val_predictions = tf.argmax(val_logits, axis=1)
        val_true_labels = tf.argmax(tf.gather(y_tf, val_indices_tf), axis=1)
        val_accuracy = tf.reduce_mean(tf.cast(tf.equal(val_predictions, val_true_labels), tf.float32))
        val_accuracies.append(val_accuracy.numpy())
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.numpy():.4f}, Val Acc: {val_accuracy.numpy():.4f}")
    
    # Final evaluation
    final_logits = gcn_model(X_tf, adj_tf, training=False)
    test_logits = tf.gather(final_logits, test_indices_tf)
    test_predictions = tf.argmax(test_logits, axis=1)
    test_true_labels = tf.argmax(tf.gather(y_tf, test_indices_tf), axis=1)
    test_accuracy = tf.reduce_mean(tf.cast(tf.equal(test_predictions, test_true_labels), tf.float32))
    
    print(f"GCN Test Accuracy: {test_accuracy.numpy():.4f}")
    
    return gcn_model, test_accuracy.numpy(), train_losses, val_accuracies

# Train GCN model
gcn_model, gcn_test_accuracy, train_losses, val_accuracies = train_gcn_model(
    X_normalized, adj_tf, train_indices, val_indices, test_indices, y_labels, num_classes
)
```

---

## Cell 21: Plot GCN Training Progress

```python
# Plot training progress
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("GCN Training Loss")
plt.grid(True)
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(val_accuracies, label="Validation Accuracy", color="green")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("GCN Validation Accuracy")
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()
```

---

## Cell 22: Exercise - Extract and Visualize GCN Embeddings

Complete the function to extract deep embeddings from the first GCN layer.

```python
def extract_gcn_embeddings(gcn_model, X_tf, adj_tf):
    """Extract deep embeddings from the first GCN layer."""
    @tf.function
    def get_embeddings():
        # TODO: Get embeddings from the first GCN layer
        hidden = gcn_model.gcn_layer1(X_tf, adj_tf)
        return ...  # TODO: Apply ReLU activation
    
    return get_embeddings().numpy()

# Extract and visualize GCN embeddings
X_tf = tf.convert_to_tensor(X_normalized.toarray(), dtype=tf.float32)
gcn_embeddings = extract_gcn_embeddings(gcn_model, X_tf, adj_tf)
plot_feature_tsne(gcn_embeddings, y_labels, "t-SNE of GCN Deep Embeddings")
```

**Answer:**
```python
# return tf.nn.relu(hidden)
```

---

# Part 7: Results Analysis and Comparison

## Cell 23: Summary of Results

```python
print("\n" + "="*60)
print("FINAL RESULTS SUMMARY")
print("="*60)
print(f"Shallow Encoder Test Accuracy:     {shallow_encoder_accuracy:.4f}")
print(f"Node2Vec Embeddings Test Accuracy: {node2vec_acc:.4f}")
print(f"Combined Features Test Accuracy:   {combined_acc:.4f}")
print(f"Raw Features Test Accuracy:        {raw_features_acc:.4f}")
print(f"GCN Test Accuracy:                 {gcn_test_accuracy:.4f}")
print("="*60)
```

---

## Cell 24: Visual Comparison of All Methods

```python
# Create comparison plot
methods = ['Shallow\nEncoder', 'Node2Vec\nEmbeddings', 'Combined\nFeatures', 'Raw\nFeatures', 'GCN']
accuracies = [shallow_encoder_accuracy, node2vec_acc, combined_acc, raw_features_acc, gcn_test_accuracy]

plt.figure(figsize=(10, 6))
bars = plt.bar(methods, accuracies, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral'])
plt.title('Node Classification Performance Comparison')
plt.ylabel('Test Accuracy')
plt.ylim(0, 1)

# Add value labels on bars
for bar, acc in zip(bars, accuracies):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
```

---

# Part 8: Discussion and Analysis

## Cell 25: Key Insights

```python
print("=== KEY INSIGHTS FROM THE TUTORIAL ===")
print()
print("1. SHALLOW ENCODER:")
print("   - Simple baseline that learns unique embeddings for each node")
print("   - Does not leverage graph structure or node features")
print("   - Performance depends on having enough training data per node")
print()
print("2. NODE2VEC:")
print("   - Unsupervised method that captures graph structure through random walks")
print("   - Can be combined with original features for better performance")
print("   - Learns embeddings that preserve local neighborhood information")
print()
print("3. GRAPH CONVOLUTIONAL NETWORK:")
print("   - Leverages both graph structure AND node features")
print("   - Uses message passing to aggregate information from neighbors")
print("   - Often achieves best performance on graph-structured data")
print()
print("4. FEATURE ANALYSIS:")
print("   - Raw features alone can be quite effective for some datasets")
print("   - Combining graph embeddings with features often improves results")
print("   - Graph structure provides complementary information to node features")
```

---

## Cell 26: Exercise - Experiment with Hyperparameters

Try modifying some hyperparameters and observe the effects. Complete this experimental analysis:

```python
def quick_gcn_experiment(hidden_dim, learning_rate):
    """Run a quick GCN experiment with different hyperparameters."""
    
    # TODO: Create a new GCN model with the specified hidden_dim
    experimental_model = ...  # TODO
    
    # TODO: Create optimizer with specified learning_rate
    optimizer = ...  # TODO
    
    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    
    # Quick training (just 10 epochs)
    X_tf = tf.convert_to_tensor(X_normalized.toarray(), dtype=tf.float32)
    y_onehot = to_categorical(y_labels, num_classes=num_classes)
    y_tf = tf.convert_to_tensor(y_onehot, dtype=tf.float32)
    train_indices_tf = tf.convert_to_tensor(train_indices, dtype=tf.int32)
    test_indices_tf = tf.convert_to_tensor(test_indices, dtype=tf.int32)
    
    @tf.function
    def train_step():
        with tf.GradientTape() as tape:
            logits = experimental_model(X_tf, adj_tf, training=True)
            train_logits = tf.gather(logits, train_indices_tf)
            train_labels = tf.gather(y_tf, train_indices_tf)
            loss = loss_fn(train_labels, train_logits)
        
        gradients = tape.gradient(loss, experimental_model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, experimental_model.trainable_variables))
        return loss
    
    # Quick training
    for epoch in range(10):
        train_step()
    
    # Evaluate
    final_logits = experimental_model(X_tf, adj_tf, training=False)
    test_logits = tf.gather(final_logits, test_indices_tf)
    test_predictions = tf.argmax(test_logits, axis=1)
    test_true_labels = tf.argmax(tf.gather(y_tf, test_indices_tf), axis=1)
    test_accuracy = tf.reduce_mean(tf.cast(tf.equal(test_predictions, test_true_labels), tf.float32))
    
    return test_accuracy.numpy()

# Experiment with different hyperparameters
print("=== HYPERPARAMETER EXPERIMENTS ===")
print("Original GCN (hidden_dim=16, lr=0.01):", f"{gcn_test_accuracy:.4f}")

# TODO: Try different hidden dimensions
hidden_dims = [8, 32, 64]
for dim in hidden_dims:
    acc = quick_gcn_experiment(dim, 0.01)
    print(f"Hidden dim {dim}: {acc:.4f}")

# TODO: Try different learning rates  
learning_rates = [0.005, 0.02, 0.05]
for lr in learning_rates:
    acc = quick_gcn_experiment(16, lr)
    print(f"Learning rate {lr}: {acc:.4f}")
```

**Answer:**
```python
# experimental_model = GCNModel(hidden_dim, num_classes)
# optimizer = Adam(learning_rate=learning_rate)
```

---

## Cell 27: Conclusion

```python
print("=== TUTORIAL COMPLETE! ===")
print()
print("üéâ Congratulations! You have successfully:")
print("   ‚úì Loaded and preprocessed a real graph dataset")
print("   ‚úì Implemented three different node classification approaches")
print("   ‚úì Compared the performance of different methods")
print("   ‚úì Visualized embeddings and results")
print("   ‚úì Experimented with hyperparameters")
print()
print("üîç Key Takeaways:")
print("   ‚Ä¢ Graph structure provides valuable information for node classification")
print("   ‚Ä¢ Different methods have different strengths and use cases")
print("   ‚Ä¢ GCNs can effectively combine graph structure with node features")
print("   ‚Ä¢ Visualization helps understand what models learn")
print()
print("üöÄ Next Steps:")
print("   ‚Ä¢ Try implementing other GNN variants (GraphSAGE, GAT)")
print("   ‚Ä¢ Experiment with other graph datasets")
print("   ‚Ä¢ Explore graph-level tasks (graph classification)")
print("   ‚Ä¢ Study more advanced graph neural network architectures")
```

---

# Appendix: Additional Exercises (Optional)

## Exercise A: Implement GraphSAGE Sampling

For advanced students, try implementing a simple version of GraphSAGE sampling:

```python
def sample_neighbors(graph_object, node, num_samples=5):
    """Sample a fixed number of neighbors for GraphSAGE."""
    neighbors = graph_object.children(node)
    if len(neighbors) <= num_samples:
        return neighbors
    else:
        return random.sample(neighbors, num_samples)

# TODO: Use this in a modified GCN layer that samples neighbors
# This is left as an advanced exercise for interested students
```

## Exercise B: Attention Mechanism

Try adding attention weights to the GCN layer:

```python
class AttentionGCNLayer(tf.keras.layers.Layer):
    """GCN Layer with attention mechanism."""
    
    def __init__(self, output_dim):
        super().__init__()
        self.output_dim = output_dim
        self.weight_transform = tf.keras.layers.Dense(output_dim, use_bias=False)
        # TODO: Add attention mechanism
        # This is left as an advanced exercise
    
    def call(self, features, adj_normalized):
        # TODO: Implement attention-based aggregation
        pass
```

---

**End of Tutorial**

*This tutorial provided a comprehensive introduction to Graph Neural Networks for node classification. You learned three different approaches and gained hands-on experience with real graph data. Keep exploring the exciting field of graph machine learning!*